# Project Idea
Explore the complexities of feedback (e.g. sensorimotor) loops through the use of simulated agents exhibiting different degrees of representation (on a continuum from representation-free to representation-rich). Does an intelligent agent (or organism) require a minimal (or maximum) level of representational complexity (mapping between phenomena and neurons) to produce and act upon feedback? Implementation might include Bayesian models, agent-based models, or something as simple as a pendulum.

### Scientific context 
 We also know that feedback plays a critical role in behavioral regulation, observed in a wide variety of systems: autonomic processes, movement, and social interaction. Using a variety of representational frameworks, how can we characterize this complexity? Does an intelligent agent (or organism) require a minimal level of representational complexity to produce and act upon feedback? 

### Specific question
What is the tradeoff between feedback and performance given representational models at different levels of complexity?

* starting from a zero representational model, what is the tradeoff agents (or organisms) make in terms of performance for a certain level of feedback complexity? 

#### Subquestions
How can you model top-down feedback in an artificial neural network? How do you model behavioral feedback with different degrees of complexity (e.g. first-order, nonlinear, etc)?

If we increase the degree of representation (mapping between behavioral outcomes or environmental objects and the brain), does this help make use of feedback more efficiently? 

### Data set
Mouse dataset (or EEG time-series) to train behavioral agents.

### Techniques
Bayesian model, Agent-based Model, or Reinforcement Learning.

### Controls
No-representation feed-forward model of behavior.

