{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoDseNg1gfbl"
   },
   "source": [
    "# Preliminary setup and data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGBQ_oIugfbm"
   },
   "source": [
    "Users will need to install the `PsyTrack` package (version 1.3), by running the cell below. We also define a variable `SPATH` which is the directory where all data files and figures produced by the notebook will be saved.\n",
    "\n",
    "Several standard Python packages are used: `numpy`, `scipy`, `matplotlib`, and `pandas`. We import all these libraries before proceeding, as well as setting several parameters in `matplotlib` to standardize the figures produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:04:43.698269Z",
     "start_time": "2020-04-23T10:04:40.446048Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QSa5tS2Ngfbn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Install then import PsyTrack\n",
    "!pip install psytrack==1.3\n",
    "import psytrack as psy\n",
    "\n",
    "# Set save path for all figures, decide whether to save permanently\n",
    "SPATH = \"ColabFigureData/\"\n",
    "!mkdir -p \"{SPATH}\"\n",
    "\n",
    "# Set matplotlib defaults for making files consistent in Illustrator\n",
    "colors = psy.COLORS\n",
    "zorder = psy.ZORDER\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.facecolor'] = (1,1,1,0)\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'     # not available in Colab\n",
    "# plt.rcParams['font.sans-serif'] = 'Helvetica'  # not available in Colab\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FqDWGYngfbs"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VB3VveZugfbs"
   },
   "source": [
    "## Download and pre-process IBL mouse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWmLrfQAgfbt"
   },
   "source": [
    "1) Use the command below to instal the IBL's [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) Python library, download the [IBL mouse behavior dataset](https://doi.org/10.6084/m9.figshare.11636748.v7) _(version 7, uploaded February 7, 2020)_ to our `SPATH` directory as `ibl-behavior-data-Dec2019.zip`, and unzip the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:17:34.515838Z",
     "start_time": "2020-04-18T01:17:34.476422Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SomAMEKhgfbu"
   },
   "outputs": [],
   "source": [
    "!pip install ibllib\n",
    "!wget -nc -O \"{SPATH}ibl-behavior-data-Dec2019.zip\" \"https://ndownloader.figshare.com/files/21623715\"\n",
    "!unzip -d \"{SPATH}\" -n \"{SPATH}ibl-behavior-data-Dec2019.zip\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mqj3mF1sgfbx"
   },
   "source": [
    "2) Use the [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) library to build a table of all the subject and session data contained within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:18:08.044366Z",
     "start_time": "2020-04-18T01:17:36.492208Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "eoXYyz62gfby",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from oneibl.onelight import ONE\n",
    "\n",
    "ibl_data_path = SPATH + 'ibl-behavioral-data-Dec2019'\n",
    "current_cwd = os.getcwd()\n",
    "os.chdir(ibl_data_path)\n",
    "\n",
    "# Search all sessions that have these dataset types.\n",
    "required_vars = ['_ibl_trials.choice', '_ibl_trials.contrastLeft',\n",
    "                 '_ibl_trials.contrastRight','_ibl_trials.feedbackType']\n",
    "one = ONE()\n",
    "eids = one.search(required_vars)\n",
    "\n",
    "mouseData = pd.DataFrame()\n",
    "for eid in eids:\n",
    "    lab, _, subject, date, session = eid.split(\"/\")    \n",
    "    sess_vars = {\n",
    "        \"eid\": eid,\n",
    "        \"lab\": lab,\n",
    "        \"subject\": subject,\n",
    "        \"date\": date,\n",
    "        \"session\": session,\n",
    "    }\n",
    "    mouseData = mouseData.append(sess_vars, sort=True, ignore_index=True)\n",
    "\n",
    "os.chdir(current_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDOOSP3ggfb4"
   },
   "source": [
    "3) Next, we use the table of session data to process the raw trial data below into a single CSV file, `ibl_processed.csv`, saved to our `SPATH` directory.\n",
    "\n",
    "There are several known anomalies in the raw data:\n",
    " - CSHL_002 codes left contrasts as negative right contrasts on 81 trials (these trials are corrected)\n",
    " - ZM_1084 has `feedbackType` of 0 for 3 trials (these trials are omitted)\n",
    " - DY_009, DY_010, DY_011 each have <5000 trials total (no adjustment)\n",
    " - ZM_1367, ZM_1369, ZM_1371, ZM_1372, and ZM_1743 are shown non-standard contrast values of 0.04 and 0.08 (no adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:44.870215Z",
     "start_time": "2020-04-18T01:18:08.047871Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xZVDIrTkgfb5"
   },
   "outputs": [],
   "source": [
    "all_vars = [\"contrastLeft\", \"contrastRight\", \"choice\", \"feedbackType\", \"probabilityLeft\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "all_mice = []\n",
    "for j, s in enumerate(mouseData[\"subject\"].unique()):\n",
    "    print(\"\\rProcessing \" + str(j+1) + \" of \" + str(len(mouseData[\"subject\"].unique())), end=\"\")\n",
    "    mouse = mouseData[mouseData[\"subject\"]==s].sort_values(['date', 'session']).reset_index()\n",
    "    for i, row in mouse.iterrows():\n",
    "        myVars = {}\n",
    "        for v in all_vars:\n",
    "            filename = \"_ibl_trials.\" + v + \".npy\"\n",
    "            var_file = os.path.join(ibl_data_path, row.eid, \"alf\", filename)\n",
    "            myVars[v] = list(np.load(var_file).flatten())\n",
    "\n",
    "        num_trials = len(myVars[v])\n",
    "        myVars['lab'] = [row.lab]*num_trials\n",
    "        myVars['subject'] = [row.subject]*num_trials\n",
    "        myVars['date'] = [row.date]*num_trials\n",
    "        myVars['session'] = [row.session]*num_trials\n",
    "\n",
    "        all_mice += [pd.DataFrame(myVars, columns=myVars.keys())]\n",
    "        \n",
    "df = pd.concat(all_mice, ignore_index=True)\n",
    "\n",
    "df = df[df['choice'] != 0]        # dump mistrials\n",
    "df = df[df['feedbackType'] != 0]  # 3 anomalous trials from ZM_1084, omit\n",
    "df.loc[np.isnan(df['contrastLeft']), \"contrastLeft\"] = 0\n",
    "df.loc[np.isnan(df['contrastRight']), \"contrastRight\"] = 0\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastLeft\"] = np.abs(df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"])\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"] = 0  # 81 anomalous trials in CSHL_002, correct\n",
    "df[\"answer\"] = df[\"feedbackType\"] * df[\"choice\"]      # new column to indicate correct answer\n",
    "df.loc[df[\"answer\"]==1, \"answer\"] = 0\n",
    "df.loc[df[\"answer\"]==-1, \"answer\"] = 1\n",
    "df.loc[df[\"feedbackType\"]==-1, \"feedbackType\"] = 0\n",
    "df.loc[df[\"choice\"]==1, \"choice\"] = 0\n",
    "df.loc[df[\"choice\"]==-1, \"choice\"] = 1\n",
    "df.to_csv(SPATH+\"ibl_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdDIQpC6gfb_"
   },
   "source": [
    "4) Next we run a few sanity checks on our data, to make sure everything processed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:45.504667Z",
     "start_time": "2020-04-18T01:19:44.873131Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UONTFii8gfb_"
   },
   "outputs": [],
   "source": [
    "print(\"contrastLeft: \", np.unique(df['contrastLeft']))   # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"contrastRight: \", np.unique(df['contrastRight'])) # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"choice: \", np.unique(df['choice']))               # [0, 1]\n",
    "print(\"feedbackType: \", np.unique(df['feedbackType']))   # [0, 1]\n",
    "print(\"answer: \", np.unique(df['answer']))               # [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVDFZXBogfcE"
   },
   "source": [
    "5) Finally, we define a function `getMouse` that extracts the data for a single mouse from our CSV file, and returns it as a PsyTrack compatible `dict`. We will use this function to access IBL mouse data in the figures below. Note the keyword argument and default value $p=5$ which controls the strength of the $\\tanh$ transformation on the contrast values. See Figure S3 and the STAR Methods of the accompanying paper for more details.\n",
    "\n",
    "**Note:** Once steps 1-5 have been run once, only step 5 will need to be run on subsequent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:48.906769Z",
     "start_time": "2020-04-18T01:19:45.508884Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uC-l-HP_gfcF"
   },
   "outputs": [],
   "source": [
    "ibl_mouse_data_path = SPATH + \"ibl_processed.csv\"\n",
    "\n",
    "MOUSE_DF = pd.read_csv(ibl_mouse_data_path)\n",
    "def getMouse(subject, p=5):\n",
    "    df = MOUSE_DF[MOUSE_DF['subject']==subject]   # Restrict data to the subject specified\n",
    "    \n",
    "    cL = np.tanh(p*df['contrastLeft'])/np.tanh(p)   # tanh transformation of left contrasts\n",
    "    cR = np.tanh(p*df['contrastRight'])/np.tanh(p)  # tanh transformation of right contrasts\n",
    "    inputs = dict(cL = np.array(cL)[:, None], cR = np.array(cR)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject=subject,\n",
    "        lab=np.unique(df[\"lab\"])[0],\n",
    "        contrastLeft=np.array(df['contrastLeft']),\n",
    "        contrastRight=np.array(df['contrastRight']),\n",
    "        date=np.array(df['date']),\n",
    "        dayLength=np.array(df.groupby(['date','session']).size()),\n",
    "        correct=np.array(df['feedbackType']),\n",
    "        answer=np.array(df['answer']),\n",
    "        probL=np.array(df['probabilityLeft']),\n",
    "        inputs = inputs,\n",
    "        y = np.array(df['choice'])\n",
    "    )\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi6Sc1n8gfcJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goNXR7VYgfcJ"
   },
   "source": [
    "## Download and pre-process Akrami rat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R9-mLFgzgfcK"
   },
   "source": [
    "1) Download the [Akrami rat behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_ to the `SPATH` directory as `rat_behavior.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPm05P0JslVq"
   },
   "outputs": [],
   "source": [
    "!wget -nc -O \"{SPATH}rat_behavior.csv\" \"https://ndownloader.figshare.com/files/22461707\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2u1GvUL1jjp"
   },
   "source": [
    "2) Sessions in the data corresponding to early shaping stages will be omitted, as will all mistrials (see the dataset's README for more info). The `getRat` function will then load a particular rat into a PsyTrack compatible `dict`.\n",
    "\n",
    "`getRat` has two optional parameters: `first` which will return a data set with only the first `first` trials (the default of 20,000 works for all analyses); `cutoff` excludes sessions with fewer than `cutoff` valid trials (default set to 50). We will use this function to access Akrami rat data in the figures below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:58.436964Z",
     "start_time": "2020-04-18T01:19:56.236185Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kcbHUY2tgfcn"
   },
   "outputs": [],
   "source": [
    "akrami_rat_data_path = SPATH + \"rat_behavior.csv\"\n",
    "\n",
    "RAT_DF = pd.read_csv(akrami_rat_data_path)\n",
    "RAT_DF = RAT_DF[RAT_DF[\"training_stage\"] > 2]  # Remove trials from early training\n",
    "RAT_DF = RAT_DF[~np.isnan(RAT_DF[\"choice\"])]   # Remove mistrials\n",
    "def getRat(subject, first=20000, cutoff=50):\n",
    "\n",
    "    df = RAT_DF[RAT_DF['subject_id']==subject]  # restrict dataset to single subject\n",
    "    df = df[:first]  # restrict to \"first\" trials of data\n",
    "    # remove sessions with fewer than \"cutoff\" valid trials\n",
    "    df = df.groupby('session').filter(lambda x: len(x) >= cutoff)   \n",
    "\n",
    "    # Normalize the stimuli to standard normal\n",
    "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
    "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
    "    \n",
    "    # Determine which trials do not have a valid previous trial (mistrial or session boundary)\n",
    "    t = np.array(df[\"trial\"])\n",
    "    prior = ((t[1:] - t[:-1]) == 1).astype(int)\n",
    "    prior = np.hstack(([0], prior))\n",
    "\n",
    "    # Calculate previous average tone value\n",
    "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
    "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
    "    s_avg = np.hstack(([0], s_avg))\n",
    "    s_avg = s_avg * prior  # for trials without a valid previous trial, set to 0\n",
    "\n",
    "    # Calculate previous correct answer\n",
    "    h = (df[\"correct_side\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
    "    h = np.hstack(([0], h))\n",
    "    h = h * prior  # for trials without a valid previous trial, set to 0\n",
    "    \n",
    "    # Calculate previous choice\n",
    "    c = (df[\"choice\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
    "    c = np.hstack(([0], c))\n",
    "    c = c * prior  # for trials without a valid previous trial, set to 0\n",
    "    \n",
    "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
    "                  s_b = np.array(s_b)[:, None],\n",
    "                  s_avg = np.array(s_avg)[:, None],\n",
    "                  h = np.array(h)[:, None],\n",
    "                  c = np.array(c)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject = subject,\n",
    "        inputs = inputs,\n",
    "        s_a = np.array(df['s_a']),\n",
    "        s_b = np.array(df['s_b']),\n",
    "        correct = np.array(df['hit']),\n",
    "        answer = np.array(df['correct_side']),\n",
    "        y = np.array(df['choice']),\n",
    "        dayLength=np.array(df.groupby(['session']).size()),\n",
    "    )\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EI9GPcdLgfcq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "StmsyvQsgfcq"
   },
   "source": [
    "## Download and pre-process Akrami human subject data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCDDDY5Vgfcr"
   },
   "source": [
    "1) Download the [Akrami human subject behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_. See the dataset's README for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dO5rg5Rw262N"
   },
   "outputs": [],
   "source": [
    "!wget -nc -O \"{SPATH}human_auditory.csv\" \"https://ndownloader.figshare.com/files/22461695\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4KN65Oe279h"
   },
   "source": [
    "2) We define a function `getHuman` that extracts the data for a single human subject from the downloaded CSV file, and returns it in a PsyTrack compatible `dict`. We will use this function to access Akrami human subject data in the figures below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:20:03.756258Z",
     "start_time": "2020-04-18T01:20:03.660818Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jXxcPbFkgfcs"
   },
   "outputs": [],
   "source": [
    "akrami_human_data_path = SPATH + \"human_auditory.csv\"\n",
    "\n",
    "HUMAN_DF = pd.read_csv(akrami_human_data_path)\n",
    "def getHuman(subject):\n",
    "    \n",
    "    df = HUMAN_DF[HUMAN_DF['subject_id']==subject]\n",
    "    \n",
    "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
    "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
    "    \n",
    "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
    "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
    "    s_avg = np.hstack(([0], s_avg))\n",
    "    \n",
    "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
    "                  s_b = np.array(s_b)[:, None],\n",
    "                  s_avg = np.array(s_avg)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject = subject,\n",
    "        inputs = inputs,\n",
    "        s_a = np.array(df['s_a']),\n",
    "        s_b = np.array(df['s_b']),\n",
    "        correct = np.array(df['reward']),\n",
    "        answer = np.array(df['correct_side']),\n",
    "        y = np.array(df['choice'])\n",
    "    )\n",
    "    return dat"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PsyTrack_Manuscript_Figures.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
